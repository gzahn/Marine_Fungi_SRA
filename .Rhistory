which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)
# lat_lon values that are non-standard
dat$lat_lon[which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)]
# lat_lon values that are non-standard
# convert to NA
dat$lat_lon[which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)] <- NA
dat$lat_lon[which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)]
dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() %>% unique
which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4
)
# lat_lon values that are non-standard
# convert to NA
dat$lat_lon[which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)]
dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() %>% unique
dat$lat_lon %>%
str_split(" ") %>% unique
dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist()
which(
dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() == 1 )
dat$lat_lon[which(
dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() == 1 )]
fix_list_lengths <- function(x){lapply(x, `length<-`, max(lengths(x)))}
# repair list lengths
dat$lat_lon %>% str_split(" ")
# repair list lengths
dat$lat_lon %>% str_split(" ") %>% fix_list_lengths()
# repair list lengths
dat$lat_lon %>% str_split(" ") %>% fix_list_lengths() %>% map(length) %>% unlist() %>% unique
dat$lat_lon %>% str_split(" ") %>%
fix_list_lengths()
# repair list lengths
lat_lon <-
dat$lat_lon %>% str_split(" ") %>%
fix_list_lengths()
lat_lon %>% map(1) %>% as.numeric()
lat.sign <- lat_lon %>% map(2)
lat.sign
lat.sign <- lat_lon %>% map(2) %>% unlist
lat.sign
lat.sign <- lat_lon %>% map(2) %>% unlist() %>% ifelse(. == N, 1,-1)
lat.sign <- lat_lon %>% map(2) %>% unlist()
lat.sign
ifelse(lat.sign == N, 1,-1)
lat.sign <- lat_lon %>% map(2) %>% unlist() %>% ifelse(. == "N", 1,-1)
ifelse(. == "N", 1,-1)
ifelse(lat.sign == "N", 1,-1)
lat.sign <- ifelse(lat.sign == "N", 1,-1)
lon.sign <- lat_lon %>% map(4) %>% unlist()
lon.sign
lon.sign <- ifelse(lat.sign == "E", 1,-1)
lon.sign <- lat_lon %>% map(4) %>% unlist()
lon.sign <- ifelse(lat.sign == "E", 1,-1)
lon.sign
lat_lon %>% map_dbl(1) %>% as.numeric()
lat_lon %>% map(1) %>% as.numeric()
lat_lon %>% map(1) %>% as.numeric() * lat.sign
lat.from.lat_lon <-
lat_lon %>% map(1) %>% as.numeric() * lat.sign
lon.from.lat_lon <-
lat_lon %>% map(3) %>% as.numeric() * lon.sign
lon.from.lat_lon
is.na(lon.from.lat_lon)
is.na(lon.from.lat_lon) %>% sum
# N and E are + | S and W are -
dat %>%
dplyr::select(all_of(lat_lon_cols)) %>%
skimr::skim()
names(dat)[c(lat_cols,lon_cols)]
lat.from.lat_lon
lon.from.lat_lon
dat$geographic_location_latitude
dat$geographic_location_latitude %>% as.numeric
lat.from._geoglocation <-
dat$geographic_location_latitude %>% as.numeric
lon.from.geoglocation <-
dat$geographic_location_longitude %>% unique
!is.na(lon.from.geoglocation)
lon.from.geoglocation
# geographic_location columns
lat.from._geoglocation <-
dat$geographic_location_latitude %>% as.numeric
lon.from.geoglocation <-
dat$geographic_location_longitude %>% as.numeric
!is.na(lon.from.geoglocation)
!is.na(lon.from.geoglocation) %>% sum
is.na(lon.from.geoglocation) %>% sum
lon.from.geoglocation
summary(lon.from.geoglocation)
!is.na(lon.from.geoglocation)
!is.na(lon.from.geoglocation) %>% sum
# geographic_location columns
lat.from._geoglocation <-
dat$geographic_location_latitude %>% as.numeric
lon.from.geoglocation <-
dat$geographic_location_longitude %>% as.numeric
lon.from.geoglocation
which(!is.na(lat.from._geoglocation))
# match existing values from geoglocation with lat
lat.from.lat_lon[which(!is.na(lat.from._geoglocation))]
lat.from._geoglocation[which(!is.na(lat.from._geoglocation))]
# match existing values from geoglocation with lat
lat.from.lat_lon[which(!is.na(lat.from._geoglocation))] <-
lat.from._geoglocation[which(!is.na(lat.from._geoglocation))]
which(!is.na(lon.from.geoglocation))
lon.from.geoglocation[which(!is.na(lon.from.geoglocation))]
lon.from.lat_lon[which(!is.na(lon.from.geoglocation))]
# geographic_location columns
lat.from.geoglocation <-
dat$geographic_location_latitude %>% as.numeric
lon.from.geoglocation <-
dat$geographic_location_longitude %>% as.numeric
# match existing values from geoglocation with lat and lon from 'lat_lon'
lat.from.lat_lon[which(!is.na(lat.from.geoglocation))] <-
lat.from.geoglocation[which(!is.na(lat.from.geoglocation))]
lon.from.lat_lon[which(!is.na(lon.from.geoglocation))] <-
lon.from.geoglocation[which(!is.na(lon.from.geoglocation))]
dat$latitude <- lat.from.lat_lon
dat$longitude <- lon.from.lat_lon
names(dat)
dat %>% skimr::skim()
dat %>% skimr::skim() %>% as.data.frame() %>% View
dat$bio_project
dat$
# subset to cleaned, useful columns
clean_cols <- c("bio_project","latitude","longitude")
clean_cols <- c("bio_project","latitude","longitude")
dat$bio_sample
dat$
# subset to cleaned, useful columns
clean_cols <- c("bio_project","bio_sample","latitude","longitude")
dat$experiment
dat$instrument
dat$instrument %>% grep(pattern="Illumina")
dat$instrument %>% grep(pattern="Illumina",value = TRUE)
dat$instrument %>% grep(pattern="Illumina",value = TRUE) %>% unique
dat$instrument %>% grep(pattern="Illumina",value = TRUE,invert = TRUE) %>% unique
# Remove non-illumina reads (convert to NA)
dat$instrument %>% grep(pattern="Illumina",value = TRUE,invert = TRUE) %>% unique
dat %>%
mutate(instrument = case_when(instrument %in% c("MinION","454 GS FLX+","454 GS","Sequel II") ~ NA,
TRUE ~ instument)) %>% pluck("instrument")
dat %>%
mutate(instrument = case_when(instrument %in% c("MinION","454 GS FLX+","454 GS","Sequel II") ~ NA,
TRUE ~ instrument)) %>% pluck("instrument")
dat <-
dat %>%
mutate(instrument = case_when(instrument %in% c("MinION","454 GS FLX+","454 GS","Sequel II") ~ NA,
TRUE ~ instrument))
dat$datastore_filetype
dat$library_selection
dat$library_selection %>% unique
dat$library_source
dat$library_source %>% unique
# Remove any transcriptome samples (convert to NA)
dat <-
dat %>%
mutate(library_source = case_when(library_source %in% c("METATRANSCRIPTOMIC") ~ NA,
TRUE ~ library_source))
dat$platform %>% unique
dat <-
dat %>%
mutate(instrument = case_when(platform != "ILLUMINA" ~ NA,
TRUE ~ platform))
# Remove any transcriptome samples (convert to NA)
dat <-
dat %>%
mutate(library_source = case_when(library_source %in% c("METATRANSCRIPTOMIC") ~ NA,
TRUE ~ library_source))
dat$organism %>% unique
dat$sra_study %>% unique
# subset to cleaned, useful columns
clean_cols <- c("bio_project","bio_sample","experiment","sra_study","latitude","longitude")
dat$geo_loc_name_country %>% unique
dat$geo_loc_name_country_continent %>% unique
dat$library_name %>% unique
dat$collection_date %>% unique
dat$collection_date %>% unique %>% as.date()
dat$collection_date %>% unique %>% as.Date()
dat$isolation_source %>% unique
dat$isolation_source %>% unique %>% paste(collapse = " ")
dat$isolation_source %>% unique %>% paste(collapse = " ") %>% strsplit(" ")
dat$isolation_source %>% unique %>% paste(collapse = " ") %>% strsplit(" ") %>% table
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>% strsplit(" ") %>% table %>%
as.data.frame()
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>% strsplit(" ") %>%
str_remove_all("\\") %>% table %>%
as.data.frame()
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>% strsplit(" ") %>%
str_remove_all("\\\\") %>% table %>%
as.data.frame()
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%   str_remove_all("\\\\") %>%
strsplit(" ") %>% table %>%
as.data.frame()
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",")
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("(") %>%
str_remove_all(")") %>%
strsplit(" ") %>% table %>%
as.data.frame()
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame()
str_to_lower(dat$isolation_source)
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source <- str_to_lower(dat$isolation_source) # remove capitals
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame()
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq)
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq) %>%
wordcloud::wordcloud()
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq) %>%
wordcloud::wordcloud(freq = Freq)
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq) %>%
wordcloud::wordcloud(freq = "Freq")
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq)
dat$host
dat$host %>% unique
dat$depth %>% unique
dat$depth %>% unique %>% str_split()
dat$depth %>% unique %>% strsplit()
?separate
dat$depth %>% unique %>% strsplit("[^[:alnum:]]+")
dat$depth %>% unique %>% strsplit("[^[:alnum:]]+") %>% map_chr(1)
dat$depth %>% unique %>% strsplit("[^[:alnum:]]+") %>% map_chr(1) %>% str_remove("m")
dat$depth %>% unique %>% strsplit("[^[:alnum:]]+") %>% map_chr(1) %>% str_remove("m") %>% as.numeric()
# fix depth (meters)
dat$depth <-
dat$depth %>%
strsplit("[^[:alnum:]]+") %>%
map_chr(1) %>%
str_remove("m") %>%
as.numeric()
dat$env_biome
dat$env_biome %>% unique
dat$env_feature
dat$env_feature %>% unique
dat$env_broad_scale
dat$env_broad_scale %>% unique
dat$env_material %>% unique
dat$environment_biome %>% unique
dat$environment_biome
dat$environment_biome %>% unique
dat %>% dplyr::select(starts_with("env"))
dat$env_local_scale
dat %>% dplyr::select(starts_with("env"))
dat %>% dplyr::select(starts_with("env")) %>% apply(1,paste)
dat %>% dplyr::select(starts_with("env")) %>% apply(1,paste0)
env <- dat %>% dplyr::select(starts_with("env"))
lapply(env, paste0)
apply(env, 1, paste0)
apply(env, 1, paste0) %>% as.data.frame
apply(env, 1, paste0) %>% as.data.frame %>% View
names(env)
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,env_feature,environment_biome,environment_feature,environment_material))
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,
env_feature,environment_biome,
environment_feature,environment_material,sep="_")) %>% pluck("all_env")
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,
env_feature,environment_biome,
environment_feature,environment_material,sep="_")) %>%
pluck("all_env") %>%
str_remove_all("NA_")
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,
env_feature,environment_biome,
environment_feature,environment_material,sep="_")) %>%
pluck("all_env") %>%
str_remove_all("NA_") %>%
ifelse(. == "NA",NA,.)
# generalize the environmental features
dat$environment <-
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,
env_feature,environment_biome,
environment_feature,environment_material,sep="_")) %>%
pluck("all_env") %>%
str_remove_all("NA_") %>%
ifelse(. == "NA",NA,.)
dat$marine_region
dat$environmental_medium
dat$sequencing_method
# subset to cleaned, useful columns
clean_cols <- c("bio_project","bio_sample","experiment","sra_study",
"latitude","longitude","geo_loc_name_country_continent",
"isolation_source","host","depth","environment")
dat <-
dat %>%
dplyr::select(all_of(clean_cols))
dat %>% View
dat$isolation_source %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)")
dat$isolation_source %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)")
dat$isolation_source <-
dat$isolation_source %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)")
source("~/Desktop/GIT_REPOSITORIES/Marine_Fungi_SRA/01_clean_metadata.R", echo=TRUE)
saveRDS(dat,"./metadata/cleaned_metadata.RDS")
# SETUP ####
library(readxl)
library(tidyverse)
# custom functions
fix_list_lengths <- function(x){lapply(x, `length<-`, max(lengths(x)))}
# LOAD METADATA
dat <- read_xlsx("./metadata/SraRunTable_Marine_MG.xlsx",guess_max = 100000) %>%
janitor::clean_names()
# FIX UP LATITUDE AND LONGITUDE ####
# find all variables with lat and lon
# since different people put that info in different variables
lat_cols <- names(dat) %>% grep(pattern = "lat")
lon_cols <- names(dat) %>% grep(pattern = "lon")
names(dat)[c(lat_cols,lon_cols)]
lat_lon_cols <-
c("lat_lon",
"geographic_location_latitude","geographic_location_longitude",
"latitude_start","latitude_end","longitude_start","longitude_end")
# N and E are + | S and W are -
dat %>%
dplyr::select(all_of(lat_lon_cols)) %>%
skimr::skim()
# standard lat_lon column values
# lat_lon values that are non-standard
# convert to NA
dat$lat_lon[which(dat$lat_lon %>%
str_split(" ") %>% map(length) %>% unlist() != 4)]
# repair list lengths
lat_lon <-
dat$lat_lon %>% str_split(" ") %>%
fix_list_lengths()
# get sign from N/S
lat.sign <- lat_lon %>% map(2) %>% unlist()
lat.sign <- ifelse(lat.sign == "N", 1,-1)
lon.sign <- lat_lon %>% map(4) %>% unlist()
lon.sign <- ifelse(lat.sign == "E", 1,-1)
lat.from.lat_lon <-
lat_lon %>% map(1) %>% as.numeric() * lat.sign
lon.from.lat_lon <-
lat_lon %>% map(3) %>% as.numeric() * lon.sign
lat.from.lat_lon
lon.from.lat_lon
# geographic_location columns
lat.from.geoglocation <-
dat$geographic_location_latitude %>% as.numeric
lon.from.geoglocation <-
dat$geographic_location_longitude %>% as.numeric
# match existing values from geoglocation with lat and lon from 'lat_lon'
lat.from.lat_lon[which(!is.na(lat.from.geoglocation))] <-
lat.from.geoglocation[which(!is.na(lat.from.geoglocation))]
lon.from.lat_lon[which(!is.na(lon.from.geoglocation))] <-
lon.from.geoglocation[which(!is.na(lon.from.geoglocation))]
dat$latitude <- lat.from.lat_lon
dat$longitude <- lon.from.lat_lon
names(dat)
dat %>% skimr::skim() %>% as.data.frame() %>% View
# Remove non-illumina reads (convert to NA)
dat$instrument %>% grep(pattern="Illumina",value = TRUE,invert = TRUE) %>% unique
dat <-
dat %>%
mutate(instrument = case_when(platform != "ILLUMINA" ~ NA,
TRUE ~ platform))
# Remove any transcriptome samples (convert to NA)
dat <-
dat %>%
mutate(library_source = case_when(library_source %in% c("METATRANSCRIPTOMIC") ~ NA,
TRUE ~ library_source))
# Examine isolation_source (free response, so tokenize and code into groups)
dat$isolation_source <- str_to_lower(dat$isolation_source) # remove capitals
# get feel for all values present
dat$isolation_source %>% unique %>%
paste(collapse = " ") %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)") %>%
strsplit(" ") %>% table %>%
as.data.frame() %>%
arrange(Freq)
dat$isolation_source <-
dat$isolation_source %>%
str_remove_all("\\\\") %>% # remove backslashes (who puts these in SRA!?)
str_remove_all(",") %>%
str_remove_all("\\(") %>%
str_remove_all("\\)")
# fix depth (meters)
dat$depth <-
dat$depth %>%
strsplit("[^[:alnum:]]+") %>%
map_chr(1) %>%
str_remove("m") %>%
as.numeric()
dat$env_biome %>% unique
dat$env_feature %>% unique
dat$environment_biome %>% unique
env <- dat %>% dplyr::select(starts_with("env"))
names(env)
# generalize the environmental features
dat$environment <-
env %>%
mutate(all_env = paste(env_biome,env_broad_scale,env_local_scale,
env_feature,environment_biome,
environment_feature,environment_material,sep="_")) %>%
pluck("all_env") %>%
str_remove_all("NA_") %>%
ifelse(. == "NA",NA,.)
# subset to clean(ish), useful columns
clean_cols <- c("bio_project","bio_sample","experiment","sra_study",
"latitude","longitude","geo_loc_name_country_continent",
"isolation_source","host","depth","environment")
dat <-
dat %>%
dplyr::select(all_of(clean_cols))
saveRDS(dat,"./metadata/cleaned_metadata.RDS")
system2("echo",args = "$APIKEY")
Sys.getenv("APIKEY")
usethis::edit_r_environ()
